# üîç Rapport de Diagnostic : Erreur "Text extraction resulted in empty content"

**Date** : 2025-12-08
**Site probl√©matique** : https://www.acupuncture-lyon-trinh.fr/
**Erreur** : `500 - "HTML parsing error: Text extraction resulted in empty content"`

---

## üéØ R√©sum√© Ex√©cutif

Le probl√®me n'est **PAS li√© au site web ou aux param√®tres de scraping**. C'est un probl√®me de **configuration Selenium/ChromeDriver sur Railway** combin√© √† une **r√©gression de code** dans le commit `3616f96`.

---

## üìä R√©sultats des Tests

### ‚úÖ Tests locaux (100% de r√©ussite)

| Test | Configuration | R√©sultat |
|------|--------------|----------|
| Script Python (version locale) | Selenium, sleep=2s | ‚úÖ Success - 6,713 chars markdown |
| Script Python (version locale) | Selenium, sleep=5s | ‚úÖ Success - 6,713 chars markdown |
| Script Python (version locale) | Selenium, wait_type=idle | ‚úÖ Success - 6,713 chars markdown |
| Script Python (version locale) | Playwright, wait_type=idle | ‚úÖ Success - 6,713 chars markdown |
| API locale (version stashed) | Selenium, sleep=2s | ‚úÖ Success - 7,223 bytes JSON |

**Contenu extrait** : 3,930 chars de texte visible, 37 liens, 12 titres, 39 paragraphes

### ‚ùå Tests avec version committ√©e (production)

| Test | Configuration | R√©sultat |
|------|--------------|----------|
| Script extract_urls_and_text | Selenium | ‚úÖ Fonctionne localement |
| API committ√©e locale | Selenium | ‚ùå Erreur : "/usr/bin/chromedriver not found" |
| API Railway (production) | Selenium | ‚ùå Erreur : "Text extraction resulted in empty content" |

---

## üêõ Causes Identifi√©es

### 1. **Probl√®me Principal : Selenium ne fonctionne pas sur Railway**

La version committ√©e (commit `3616f96`) configure Selenium avec :
```python
CHROMEDRIVER_PATH=/usr/bin/chromedriver
CHROME_BIN=/usr/bin/chromium
```

**Sur Railway, Selenium √©choue √† initialiser Chrome**, ce qui cause :
- Retour d'une liste HTML vide : `html_list = [[]]` ou `[None]`
- Passage de la premi√®re validation (`if not html_list or not html_list[0]`)
- √âchec de l'extraction de texte ‚Üí Erreur "Text extraction resulted in empty content"

**Logs d'erreur probables sur Railway** :
```
Chrome initialization failed: Unable to obtain driver for chrome
ValueError: The path is not a valid file: /usr/bin/chromedriver
```

### 2. **R√©gression de Code : extract_urls_and_text vs html_to_markdown**

Le commit `3616f96` a introduit une **r√©gression** :

#### Version committ√©e (Railway) - commit 3616f96
```python
urls, text = extract_urls_and_text(html_list[0], request.url)

if not text or not text.strip():
    raise ParsingError("Text extraction resulted in empty content")

return ScrapeResponse(url=request.url, urls=urls, text=text, ...)
```

#### Version locale (working directory) - FONCTIONNE
```python
markdown = html_to_markdown(html_list[0], url=request.url, include_images=request.include_images)

if not markdown or not markdown.strip():
    raise ParsingError("Markdown conversion resulted in empty content")

return ScrapeResponse(url=request.url, markdown=markdown, ...)
```

**La version locale a revert√© la r√©gression** mais n'a jamais √©t√© committ√©e !

### 3. **Configuration Docker : Chromium vs Chrome**

Le Dockerfile installe Chromium de Debian :
```dockerfile
RUN apt-get update && apt-get install -y \
    chromium \
    chromium-driver
```

**Probl√®me potentiel** :
- `chromium-driver` peut √™tre incompatible avec la version de Selenium
- Les patches Chrome dans `api.py` (version committ√©e) peuvent ne pas fonctionner avec Chromium de Debian
- `/usr/bin/chromedriver` peut ne pas √™tre ex√©cutable ou configur√© correctement

---

## üîß Solutions Recommand√©es

### ‚úÖ Solution 1 : **Commiter et d√©ployer la version locale (RECOMMAND√â)**

**Avantages** :
- ‚úÖ Fonctionne parfaitement en local avec `html_to_markdown`
- ‚úÖ Retourne du markdown propre au lieu de texte brut
- ‚úÖ Garde le param√®tre `include_images`
- ‚úÖ Code plus simple, moins de patches

**Actions** :
```bash
git add src/par_scrape/api.py
git commit -m "fix: Revert to html_to_markdown to fix empty content extraction error"
git push origin main
```

---

### ‚úÖ Solution 2 : **Passer √† Playwright par d√©faut**

Playwright est plus fiable que Selenium et ne n√©cessite pas ChromeDriver externe.

**Changements dans `api.py`** :
```python
class ScrapeRequest(BaseModel):
    fetch_using: str = Field(default="playwright")  # Chang√© de "selenium"
```

**Changements dans `Dockerfile`** :
```dockerfile
# Remplacer Chromium par Playwright browsers
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Installer Playwright apr√®s uv sync
RUN uv run playwright install --with-deps chromium
```

**Avantages** :
- ‚úÖ Plus rapide (3.34s vs 8.40s dans les tests)
- ‚úÖ Moins de probl√®mes de configuration
- ‚úÖ Pas besoin de ChromeDriver externe
- ‚úÖ Meilleure gestion du JavaScript moderne

---

### ‚úÖ Solution 3 : **Fixer Selenium sur Railway**

Si vous voulez garder Selenium, il faut corriger la configuration Docker.

**Option A : Utiliser Selenium Manager (recommand√©)**

Retirer les patches et laisser Selenium g√©rer Chrome automatiquement :

```python
# Dans api.py : SUPPRIMER tous les patches ChromeDriverManager et Chrome
# Laisser Selenium utiliser son propre Selenium Manager
```

**Option B : Installer Chrome (pas Chromium)**

```dockerfile
# Installer Google Chrome officiel au lieu de Chromium Debian
RUN wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | apt-key add - \
    && echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" > /etc/apt/sources.list.d/google-chrome.list \
    && apt-get update \
    && apt-get install -y google-chrome-stable \
    && rm -rf /var/lib/apt/lists/*

ENV CHROME_BIN=/usr/bin/google-chrome
```

---

### ‚úÖ Solution 4 : **Am√©liorer la gestion d'erreurs**

Ajouter plus de diagnostics pour identifier les probl√®mes futurs :

```python
if not html_list or not html_list[0]:
    # Ajouter logging d√©taill√©
    logger.error(f"No HTML fetched. html_list type: {type(html_list)}, length: {len(html_list) if html_list else 0}")
    if html_list:
        logger.error(f"First item: {html_list[0][:100] if html_list[0] else 'None'}")
    raise ParsingError(
        "No content was fetched from the URL. "
        "This may indicate Selenium/Playwright initialization failure."
    )

if not markdown or not markdown.strip():
    # Ajouter contexte
    html_length = len(html_list[0]) if html_list else 0
    raise ParsingError(
        f"Markdown conversion resulted in empty content. "
        f"HTML length: {html_length} chars. "
        f"Try using fetch_using='playwright' or increasing sleep_time."
    )
```

---

## üéØ Plan d'Action Recommand√©

### Phase 1 : Fix Imm√©diat (10 minutes)

1. ‚úÖ **Commiter la version locale qui fonctionne**
   ```bash
   git add src/par_scrape/api.py
   git commit -m "fix: Revert to html_to_markdown for reliable content extraction"
   git push origin main
   ```

2. ‚úÖ **V√©rifier le d√©ploiement sur Railway**
   - Attendre le red√©ploiement automatique (2-3 minutes)
   - Tester l'endpoint avec le site probl√©matique
   - V√©rifier que l'erreur dispara√Æt

### Phase 2 : Am√©lioration (30 minutes)

3. ‚úÖ **Passer √† Playwright par d√©faut**
   - Modifier `ScrapeRequest.fetch_using` default
   - Mettre √† jour le Dockerfile
   - Commiter et d√©ployer

4. ‚úÖ **Tester avec plusieurs sites**
   - Site probl√©matique : https://www.acupuncture-lyon-trinh.fr/
   - Site simple : https://example.com
   - Site JavaScript-heavy : https://react.dev

### Phase 3 : Pr√©vention (1 heure)

5. ‚úÖ **Ajouter des tests automatis√©s**
   ```python
   def test_scrape_various_sites():
       """Test scraping avec diff√©rents types de sites"""
       sites = [
           "https://example.com",  # Site simple
           "https://www.acupuncture-lyon-trinh.fr/",  # Site probl√©matique
       ]
       for site in sites:
           result = scrape(site)
           assert len(result.markdown) > 0
   ```

6. ‚úÖ **Documenter les configurations test√©es**
   - Cr√©er TROUBLESHOOTING.md
   - Lister les probl√®mes connus et solutions

---

## üìà Comparaison des Approches

| Crit√®re | html_to_markdown (local) | extract_urls_and_text (committ√©e) |
|---------|-------------------------|-----------------------------------|
| **Fonctionne localement** | ‚úÖ Oui | ‚ö†Ô∏è Oui (si pas de patch Chrome) |
| **Fonctionne sur Railway** | ‚úÖ Devrait fonctionner | ‚ùå Non (Selenium ne d√©marre pas) |
| **Format de sortie** | Markdown propre | Texte brut + URLs s√©par√©s |
| **Images** | ‚úÖ Optionnel | ‚ùå Non support√© |
| **Compatibilit√©** | ‚úÖ Haute | ‚ùå Selenium-d√©pendant |
| **Complexit√©** | ‚úÖ Simple | ‚ö†Ô∏è Complexe (patches requis) |

---

## üöÄ Commandes de D√©ploiement

### D√©ployer la fix imm√©diate
```bash
cd "/Users/valentinlopes/Desktop/week_end startup"

# V√©rifier les changements
git diff src/par_scrape/api.py

# Commiter
git add src/par_scrape/api.py
git commit -m "fix: Revert to html_to_markdown to fix empty content extraction error

- Reverts commit 3616f96 which introduced extract_urls_and_text
- html_to_markdown is more reliable and works with both Selenium and Playwright
- Restores include_images parameter
- Fixes 500 error 'Text extraction resulted in empty content' on production"

# D√©ployer
git push origin main
```

### Nettoyer les fichiers de test
```bash
# Optionnel : nettoyer les fichiers de test
rm test_*.py test_*.json
git add -A
git commit -m "chore: Remove test files"
```

---

## üìù Conclusion

Le probl√®me provient de **deux facteurs combin√©s** :

1. **Selenium ne fonctionne pas correctement sur Railway** avec la configuration actuelle
2. **Une r√©gression de code non-commit√©e** qui a √©t√© partiellement fix√©e localement

**La solution la plus rapide** : Commiter et d√©ployer la version locale.

**La solution la plus robuste** : Passer √† Playwright comme scraper par d√©faut.

**Temps estim√© pour r√©solution compl√®te** : 40 minutes (10 min fix + 30 min am√©lioration)

---

## üîó R√©f√©rences

- Commit probl√©matique : `3616f96` - "Return extracted URLs and visible text"
- Fichier principal : `src/par_scrape/api.py:267-274`
- Docker config : `Dockerfile:8-12` (installation Chromium)
- Railway config : `railway.toml`

---

**G√©n√©r√© le** : 2025-12-08 par Claude Code
